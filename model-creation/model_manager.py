#!/usr/bin/env python3
"""
çµ±åˆãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ»ç®¡ç†æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
python model_manager.py [command] [options]

ã‚³ãƒãƒ³ãƒ‰:
- quick: ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ä½œæˆ
- create: è©³ç´°ãƒ¢ãƒ‡ãƒ«ä½œæˆ
- batch: ãƒãƒƒãƒå­¦ç¿’
- evaluate: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
- compare: ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
- deploy: ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import argparse
import sys
import subprocess
import json
import logging
from pathlib import Path
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ModelManager:
    """
    çµ±åˆãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, scripts_dir=None, api_dir=None):
        self.scripts_dir = Path(scripts_dir or Path(__file__).parent)
        self.api_dir = Path(api_dir or Path(__file__).parent.parent / 'api')
        
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‘ã‚¹
        self.scripts = {
            'quick': self.scripts_dir / 'quick_model.py',
            'create': self.scripts_dir / 'create_model.py',
            'batch': self.scripts_dir / 'batch_model_training.py'
        }
    
    def print_header(self, title):
        """
        ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
        """
        print("\n" + "=" * 70)
        print(f"ğŸ  {title}")
        print("=" * 70)
    
    def quick_create(self, args):
        """
        ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        """
        self.print_header("ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ä½œæˆ")
        
        preset = getattr(args, 'preset', 'balanced')
        cmd = [sys.executable, str(self.scripts['quick']), '--preset', preset]
        
        if hasattr(args, 'output_dir') and args.output_dir:
            cmd.extend(['--output-dir', args.output_dir])
        
        try:
            result = subprocess.run(cmd, check=True, capture_output=False)
            return result.returncode == 0
        except subprocess.CalledProcessError as e:
            logger.error(f"ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    
    def detailed_create(self, args):
        """
        è©³ç´°ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        """
        self.print_header("è©³ç´°ãƒ¢ãƒ‡ãƒ«ä½œæˆ")
        
        cmd = [sys.executable, str(self.scripts['create'])]
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ 
        if hasattr(args, 'data_source'):
            cmd.extend(['--data-source', args.data_source])
        if hasattr(args, 'output_dir') and args.output_dir:
            cmd.extend(['--output-dir', args.output_dir])
        if hasattr(args, 'no_grid_search') and args.no_grid_search:
            cmd.append('--no-grid-search')
        if hasattr(args, 'cv_folds'):
            cmd.extend(['--cv-folds', str(args.cv_folds)])
        
        try:
            result = subprocess.run(cmd, check=True, capture_output=False)
            return result.returncode == 0
        except subprocess.CalledProcessError as e:
            logger.error(f"è©³ç´°ãƒ¢ãƒ‡ãƒ«ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    
    def batch_training(self, args):
        """
        ãƒãƒƒãƒå­¦ç¿’
        """
        self.print_header("ãƒãƒƒãƒå­¦ç¿’")
        
        cmd = [sys.executable, str(self.scripts['batch'])]
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ 
        if hasattr(args, 'data_source'):
            cmd.extend(['--data-source', args.data_source])
        if hasattr(args, 'output_dir') and args.output_dir:
            cmd.extend(['--output-dir', args.output_dir])
        if hasattr(args, 'max_workers'):
            cmd.extend(['--max-workers', str(args.max_workers)])
        
        try:
            result = subprocess.run(cmd, check=True, capture_output=False)
            return result.returncode == 0
        except subprocess.CalledProcessError as e:
            logger.error(f"ãƒãƒƒãƒå­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    
    def evaluate_models(self, args):
        """
        ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        """
        self.print_header("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        
        # ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨
        manage_script = Path(__file__).parent.parent / 'manage_model.sh'
        
        if manage_script.exists():
            try:
                subprocess.run([str(manage_script), 'evaluate'], check=True)
                return True
            except subprocess.CalledProcessError as e:
                logger.error(f"è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
        test_script = Path(__file__).parent.parent / 'test_model_accuracy.py'
        if test_script.exists():
            try:
                subprocess.run([sys.executable, str(test_script)], check=True)
                return True
            except subprocess.CalledProcessError as e:
                logger.error(f"ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        
        return False
    
    def compare_models(self, args):
        """
        ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
        """
        self.print_header("ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
        
        # å­¦ç¿’å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        info_files = list(self.api_dir.glob('*training_info*.json'))
        batch_files = list(self.api_dir.glob('*batch_training_results*.json'))
        quick_files = list(self.api_dir.glob('*quick_model_info*.json'))
        
        all_files = info_files + batch_files + quick_files
        
        if not all_files:
            print("âŒ æ¯”è¼ƒå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            return False
        
        print(f"ğŸ“Š {len(all_files)} å€‹ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚")
        print()
        
        models_data = []
        
        for file_path in sorted(all_files, key=lambda x: x.stat().st_mtime, reverse=True):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦æƒ…å ±æŠ½å‡ºæ–¹æ³•ã‚’å¤‰æ›´
                if 'batch_training' in file_path.name:
                    best_model = data.get('best_model', {})
                    models_data.append({
                        'file': file_path.name,
                        'timestamp': data.get('timestamp', 'Unknown'),
                        'type': 'Batch',
                        'model_name': best_model.get('name', 'Unknown'),
                        'test_r2': best_model.get('metrics', {}).get('test_r2', 0),
                        'test_mae': best_model.get('metrics', {}).get('test_mae', 0),
                        'data_size': data.get('data_info', {}).get('total_samples', 0)
                    })
                elif 'quick_model' in file_path.name:
                    models_data.append({
                        'file': file_path.name,
                        'timestamp': data.get('timestamp', 'Unknown'),
                        'type': 'Quick',
                        'model_name': data.get('preset', 'Unknown'),
                        'test_r2': data.get('metrics', {}).get('test_r2', 0),
                        'test_mae': data.get('metrics', {}).get('test_mae', 0),
                        'data_size': data.get('data_info', {}).get('total_samples', 0)
                    })
                else:
                    # é€šå¸¸ã®å­¦ç¿’æƒ…å ±
                    models_data.append({
                        'file': file_path.name,
                        'timestamp': data.get('timestamp', 'Unknown'),
                        'type': 'Detailed',
                        'model_name': data.get('best_model', 'Unknown'),
                        'test_r2': data.get('metrics', {}).get('test_r2', 0),
                        'test_mae': data.get('metrics', {}).get('test_mae', 0),
                        'data_size': data.get('data_size', 0)
                    })
                
            except Exception as e:
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
                continue
        
        if not models_data:
            print("âŒ æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return False
        
        # çµæœè¡¨ç¤º
        print("ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœ:")
        print("-" * 100)
        print(f"{'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—':<15} {'ã‚¿ã‚¤ãƒ—':<8} {'ãƒ¢ãƒ‡ãƒ«å':<20} {'Test RÂ²':<10} {'Test MAE':<15} {'ãƒ‡ãƒ¼ã‚¿æ•°':<10}")
        print("-" * 100)
        
        for model in sorted(models_data, key=lambda x: x['test_r2'], reverse=True):
            timestamp = model['timestamp'][:10] if len(model['timestamp']) > 10 else model['timestamp']
            print(f"{timestamp:<15} {model['type']:<8} {model['model_name']:<20} "
                  f"{model['test_r2']:<10.3f} Â¥{model['test_mae']:<13,.0f} {model['data_size']:<10,}")
        
        # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«
        best_model = max(models_data, key=lambda x: x['test_r2'])
        print()
        print(f"ğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_model['model_name']} (RÂ² = {best_model['test_r2']:.3f})")
        
        return True
    
    def deploy_model(self, args):
        """
        ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤
        """
        self.print_header("ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤")
        
        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        model_file = self.api_dir / 'valuation_model.joblib'
        encoders_file = self.api_dir / 'label_encoders.joblib'
        
        if not model_file.exists():
            print("âŒ ãƒ‡ãƒ—ãƒ­ã‚¤å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            return False
        
        print("ğŸ“¦ ãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"  âœ… {model_file.name} ({model_file.stat().st_size:,} bytes)")
        
        if encoders_file.exists():
            print(f"  âœ… {encoders_file.name} ({encoders_file.stat().st_size:,} bytes)")
        else:
            print(f"  âš ï¸ {encoders_file.name} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        
        print()
        print("ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †:")
        print("1. docker-compose restart api  # APIã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•")
        print("2. ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ:")
        print("   python test_model_accuracy.py")
        print("3. æœ¬ç•ªç’°å¢ƒã¸ã®å±•é–‹:")
        print("   ./deploy/ecr-deploy.sh  # ECRãƒ‡ãƒ—ãƒ­ã‚¤")
        
        # APIã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•ã®ç¢ºèª
        restart = input("\nAPIã‚µãƒ¼ãƒãƒ¼ã‚’å†èµ·å‹•ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower().strip()
        if restart == 'y':
            try:
                subprocess.run(['docker-compose', 'restart', 'api'], 
                             cwd=Path(__file__).parent.parent, check=True)
                print("âœ… APIã‚µãƒ¼ãƒãƒ¼ãŒå†èµ·å‹•ã•ã‚Œã¾ã—ãŸã€‚")
                
                # ç°¡æ˜“ãƒ†ã‚¹ãƒˆ
                import time
                print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’å¾…æ©Ÿä¸­...")
                time.sleep(5)
                
                test_script = Path(__file__).parent.parent / 'test_model_accuracy.py'
                if test_script.exists():
                    subprocess.run([sys.executable, str(test_script)], check=False)
                
                return True
            except subprocess.CalledProcessError as e:
                logger.error(f"APIã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return False
        
        return True
    
    def show_status(self):
        """
        ç¾åœ¨ã®çŠ¶æ…‹è¡¨ç¤º
        """
        self.print_header("ãƒ¢ãƒ‡ãƒ«ç®¡ç†çŠ¶æ…‹")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        model_file = self.api_dir / 'valuation_model.joblib'
        encoders_file = self.api_dir / 'label_encoders.joblib'
        
        print("ğŸ“ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹:")
        if model_file.exists():
            mtime = datetime.fromtimestamp(model_file.stat().st_mtime)
            print(f"  âœ… valuation_model.joblib ({model_file.stat().st_size:,} bytes, {mtime.strftime('%Y-%m-%d %H:%M:%S')})")
        else:
            print(f"  âŒ valuation_model.joblib (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        
        if encoders_file.exists():
            mtime = datetime.fromtimestamp(encoders_file.stat().st_mtime)
            print(f"  âœ… label_encoders.joblib ({encoders_file.stat().st_size:,} bytes, {mtime.strftime('%Y-%m-%d %H:%M:%S')})")
        else:
            print(f"  âŒ label_encoders.joblib (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        
        # å­¦ç¿’å±¥æ­´
        info_files = list(self.api_dir.glob('*training_info*.json'))
        info_files += list(self.api_dir.glob('*batch_training_results*.json'))
        info_files += list(self.api_dir.glob('*quick_model_info*.json'))
        
        print(f"\nğŸ“Š å­¦ç¿’å±¥æ­´: {len(info_files)} ä»¶")
        for file_path in sorted(info_files, key=lambda x: x.stat().st_mtime, reverse=True)[:3]:
            mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
            print(f"  ğŸ“„ {file_path.name} ({mtime.strftime('%Y-%m-%d %H:%M:%S')})")
        
        # APIã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹
        print(f"\nğŸŒ APIã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹:")
        try:
            import requests
            response = requests.get('http://localhost:3001/health', timeout=3)
            if response.status_code == 200:
                print("  âœ… APIã‚µãƒ¼ãƒãƒ¼ç¨¼åƒä¸­")
                
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—è©¦è¡Œ
                try:
                    model_info = requests.get('http://localhost:3001/api/model/info', timeout=3)
                    if model_info.status_code == 200:
                        info_data = model_info.json()
                        print(f"  ğŸ“Š ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿: {info_data.get('model_loaded', False)}")
                    else:
                        print("  âš ï¸ ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼")
                except:
                    print("  âš ï¸ ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—å¤±æ•—")
            else:
                print("  âŒ APIã‚µãƒ¼ãƒãƒ¼å¿œç­”ã‚¨ãƒ©ãƒ¼")
        except:
            print("  âŒ APIã‚µãƒ¼ãƒãƒ¼æ¥ç¶šå¤±æ•—")
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        print(f"\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        if not model_file.exists():
            print("  1. ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„: python model_manager.py quick")
        else:
            print("  1. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡: python model_manager.py evaluate")
            print("  2. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ: python model_manager.py compare")
            print("  3. æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ä½œæˆ: python model_manager.py create")


def main():
    parser = argparse.ArgumentParser(description='çµ±åˆãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    subparsers = parser.add_subparsers(dest='command', help='å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰')
    
    # ã‚¯ã‚¤ãƒƒã‚¯ä½œæˆ
    quick_parser = subparsers.add_parser('quick', help='ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ä½œæˆ')
    quick_parser.add_argument('--preset', choices=['fast', 'balanced', 'best'], 
                             default='balanced', help='å­¦ç¿’ãƒ—ãƒªã‚»ãƒƒãƒˆ')
    quick_parser.add_argument('--output-dir', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    # è©³ç´°ä½œæˆ
    create_parser = subparsers.add_parser('create', help='è©³ç´°ãƒ¢ãƒ‡ãƒ«ä½œæˆ')
    create_parser.add_argument('--data-source', choices=['sample', 'mlit', 'csv'], 
                              default='sample', help='ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹')
    create_parser.add_argument('--output-dir', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    create_parser.add_argument('--no-grid-search', action='store_true',
                              help='ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’ã‚¹ã‚­ãƒƒãƒ—')
    create_parser.add_argument('--cv-folds', type=int, default=5,
                              help='äº¤å·®æ¤œè¨¼ã®åˆ†å‰²æ•°')
    
    # ãƒãƒƒãƒå­¦ç¿’
    batch_parser = subparsers.add_parser('batch', help='ãƒãƒƒãƒå­¦ç¿’')
    batch_parser.add_argument('--data-source', choices=['sample', 'mlit', 'csv'], 
                             default='sample', help='ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹')
    batch_parser.add_argument('--output-dir', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    batch_parser.add_argument('--max-workers', type=int, help='æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°')
    
    # è©•ä¾¡
    subparsers.add_parser('evaluate', help='ãƒ¢ãƒ‡ãƒ«è©•ä¾¡')
    
    # æ¯”è¼ƒ
    subparsers.add_parser('compare', help='ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ')
    
    # ãƒ‡ãƒ—ãƒ­ã‚¤
    subparsers.add_parser('deploy', help='ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤')
    
    # çŠ¶æ…‹è¡¨ç¤º
    subparsers.add_parser('status', help='ç¾åœ¨ã®çŠ¶æ…‹è¡¨ç¤º')
    
    args = parser.parse_args()
    
    if not args.command:
        # ã‚³ãƒãƒ³ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯çŠ¶æ…‹è¡¨ç¤º
        args.command = 'status'
    
    # ãƒ¢ãƒ‡ãƒ«ç®¡ç†å™¨ã®åˆæœŸåŒ–
    manager = ModelManager()
    
    # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
    if args.command == 'quick':
        success = manager.quick_create(args)
    elif args.command == 'create':
        success = manager.detailed_create(args)
    elif args.command == 'batch':
        success = manager.batch_training(args)
    elif args.command == 'evaluate':
        success = manager.evaluate_models(args)
    elif args.command == 'compare':
        success = manager.compare_models(args)
    elif args.command == 'deploy':
        success = manager.deploy_model(args)
    elif args.command == 'status':
        manager.show_status()
        success = True
    else:
        print(f"æœªçŸ¥ã®ã‚³ãƒãƒ³ãƒ‰: {args.command}")
        success = False
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()